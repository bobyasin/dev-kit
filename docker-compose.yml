name: local-dev

services:
  # -----------------------------------------
  # RabbitMQ + Management
  # -----------------------------------------
  rabbitmq:
    image: heidiks/rabbitmq-delayed-message-exchange:3.12.10-management
    container_name: rabbitmq-local
    hostname: rabbitmq-local
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: test
      RABBITMQ_DEFAULT_PASS: test
      RABBITMQ_LOAD_DEFINITIONS: "1"
      RABBITMQ_DEFINITIONS_FILE: /etc/rabbitmq/definitions.json
      # Ensure ports are explicitly bound
      RABBITMQ_NODE_PORT: 5672
      RABBITMQ_DIST_PORT: 25672
    ports:
      # AMQP port - explicitly bind to all interfaces
      - "0.0.0.0:5672:5672"
      # Management UI port - explicitly bind to all interfaces
      - "0.0.0.0:15672:15672"
      # Distribution port for clustering (optional but good to have)
      - "0.0.0.0:25672:25672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "status"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - devnet
    # Ensure container dependencies and startup order
    depends_on: []
    # Resource limits to prevent OOM kills
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # MySQL 8
  # -----------------------------------------
  mysql:
    image: mysql:8.4
    container_name: mysql-local
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: rootpass
      MYSQL_DATABASE: appdb
      MYSQL_USER: appuser
      MYSQL_PASSWORD: apppass
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # PostgreSQL 16
  # -----------------------------------------
  postgres:
    image: postgres:16
    container_name: postgres-local
    restart: unless-stopped
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: apppass
      POSTGRES_DB: appdb
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=trust"
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser -d appdb"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # MongoDB (Single Instance for Development)
  # -----------------------------------------
  mongodb:
    image: mongo:8.0.6
    container_name: mongodb-local
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: adminpass
      MONGO_INITDB_DATABASE: appdb
    volumes:
      - mongodb-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # MongoDB Replica Set - Primary
  # -----------------------------------------
  mongo-primary:
    image: mongo:8.0.6
    container_name: mongo-primary
    restart: unless-stopped
    ports:
      - "27018:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: adminpass
      MONGO_INITDB_DATABASE: appdb
    volumes:
      - mongo-primary-data:/data/db
      - ./mongodb-cluster/keyfile/mongodb-keyfile:/opt/keyfile/mongodb-keyfile:ro
    command:
      [
        "mongod",
        "--replSet",
        "rs0",
        "--bind_ip_all",
        "--keyFile",
        "/opt/keyfile/mongodb-keyfile",
      ]
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # MongoDB Replica Set - Secondary 1
  # -----------------------------------------
  mongo-secondary1:
    image: mongo:8.0.6
    container_name: mongo-secondary1
    restart: unless-stopped
    ports:
      - "27019:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: adminpass
      MONGO_INITDB_DATABASE: appdb
    volumes:
      - mongo-secondary1-data:/data/db
      - ./mongodb-cluster/keyfile/mongodb-keyfile:/opt/keyfile/mongodb-keyfile:ro
    command:
      [
        "mongod",
        "--replSet",
        "rs0",
        "--bind_ip_all",
        "--keyFile",
        "/opt/keyfile/mongodb-keyfile",
      ]
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # MongoDB Replica Set - Secondary 2
  # -----------------------------------------
  mongo-secondary2:
    image: mongo:8.0.6
    container_name: mongo-secondary2
    restart: unless-stopped
    ports:
      - "27020:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: adminpass
      MONGO_INITDB_DATABASE: appdb
    volumes:
      - mongo-secondary2-data:/data/db
      - ./mongodb-cluster/keyfile/mongodb-keyfile:/opt/keyfile/mongodb-keyfile:ro
    command:
      [
        "mongod",
        "--replSet",
        "rs0",
        "--bind_ip_all",
        "--keyFile",
        "/opt/keyfile/mongodb-keyfile",
      ]
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Redis Standalone
  # -----------------------------------------
  redis:
    image: redis:7.4-alpine
    container_name: redis-local
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Elasticsearch
  # -----------------------------------------
  elasticsearch:
    container_name: elasticsearch-local
    restart: unless-stopped
    image: elasticsearch:8.17.2
    environment:
      - xpack.security.enabled=false
      - xpack.security.authc.api_key.enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      # Disk space management
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=85%
      - cluster.routing.allocation.disk.watermark.high=90%
      - cluster.routing.allocation.disk.watermark.flood_stage=95%
      # Index lifecycle management
      - xpack.ilm.enabled=true
      - indices.lifecycle.poll_interval=10m
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./elasticsearch/ilm-policies:/usr/share/elasticsearch/ilm-policies:ro
      - ./elasticsearch/index-templates:/usr/share/elasticsearch/index-templates:ro
    healthcheck:
      test: ["CMD", "curl", "-fsSL", "http://localhost:9200/_cluster/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Kibana
  # -----------------------------------------
  kibana:
    container_name: kibana-local
    image: kibana:8.17.2
    restart: unless-stopped
    environment:
      - "ELASTICSEARCH_HOSTS=http://elasticsearch-local:9200"
      - "NODE_OPTIONS=--max-old-space-size=1024"
      - "SUPPRESS_NO_CONFIG_WARNING=true"
      - "OPENSSL_CONF="
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    ports:
      - "5601:5601"
    healthcheck:
      test: ["CMD", "curl", "-fsSL", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 50
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # APM Server
  # -----------------------------------------
  apm-server:
    container_name: apm-server-local
    image: docker.elastic.co/apm/apm-server:8.17.2
    restart: unless-stopped
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
      - "8200:8200"
    environment:
      - "ELASTICSEARCH_HOSTS=http://elasticsearch-local:9200"
      - "KIBANA_HOST=http://kibana-local:5601"
      - "APM_SERVER_RUM_ENABLED=true"
      - "APM_SERVER_RUM_ALLOW_ORIGINS=['*']"
      - "APM_SERVER_HOST=0.0.0.0:8200"
      - "APM_SERVER_SECRET_TOKEN=apm-secret-token"
      - "LOGGING_LEVEL=info"
    healthcheck:
      test: ["CMD", "curl", "-fsSL", "http://localhost:8200/"]
      interval: 30s
      timeout: 15s
      retries: 15
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Filebeat for Log Collection
  # -----------------------------------------
  filebeat:
    container_name: filebeat-local
    image: docker.elastic.co/beats/filebeat:8.17.2
    restart: unless-stopped
    user: root
    environment:
      - "ELASTICSEARCH_HOSTS=http://elasticsearch-local:9200"
      - "KIBANA_HOST=http://kibana-local:5601"
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: ["--strict.perms=false"]
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Metricbeat for System Metrics
  # -----------------------------------------
  metricbeat:
    container_name: metricbeat-local
    image: docker.elastic.co/beats/metricbeat:8.17.2
    restart: unless-stopped
    user: root
    environment:
      - "ELASTICSEARCH_HOSTS=http://elasticsearch-local:9200"
      - "KIBANA_HOST=http://kibana-local:5601"
    volumes:
      - ./metricbeat/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /proc:/hostfs/proc:ro
      - /:/hostfs:ro
      - metricbeat-data:/usr/share/metricbeat/data
    command: ["--strict.perms=false", "--system.hostfs=/hostfs"]
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Jaeger All-in-One (Development)
  # -----------------------------------------
  jaeger:
    container_name: jaeger-local
    image: jaegertracing/all-in-one:1.53
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    ports:
      - "16686:16686" # Jaeger UI
      - "14268:14268" # Jaeger collector HTTP
      - "14250:14250" # Jaeger collector gRPC
      - "6831:6831/udp" # Jaeger agent UDP (compact)
      - "6832:6832/udp" # Jaeger agent UDP (binary)
      - "5778:5778" # Jaeger agent HTTP
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
      - "9411:9411" # Zipkin compatible endpoint
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:16686/",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Prometheus - Metrics Collection
  # -----------------------------------------
  prometheus:
    container_name: prometheus-local
    image: prom/prometheus:v2.48.1
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=15d"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Grafana - Metrics Visualization
  # -----------------------------------------
  grafana:
    container_name: grafana-local
    image: grafana/grafana:10.2.3
    restart: unless-stopped
    ports:
      - "8090:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3000/api/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Node Exporter - System Metrics
  # -----------------------------------------
  node-exporter:
    container_name: node-exporter-local
    image: prom/node-exporter:v1.7.0
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.rootfs=/rootfs"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # -----------------------------------------
  # Log Generator for Testing Live Logging
  # -----------------------------------------
  log-generator:
    container_name: log-generator-local
    image: mingrammer/flog:0.4.3
    restart: unless-stopped
    command:
      - "-f"
      - "json"
      - "-l"
      - "-t"
      - "log"
      - "-w"
      - "-s"
      - "1s"
      - "-d"
      - "1s"
    networks:
      - devnet
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# -----------------------------------------
# Persistent Volumes
# -----------------------------------------
volumes:
  rabbitmq-data:
  redis-data:
  redis-master-new-data:
  redis-slave1-new-data:
  redis-slave2-new-data:
  mysql-data:
  postgres-data:
  mongodb-data:
  mongo-primary-data:
  mongo-secondary1-data:
  mongo-secondary2-data:
  elasticsearch-data:
  filebeat-data:
  metricbeat-data:
  prometheus-data:
  grafana-data:

# -----------------------------------------
# Networks
# -----------------------------------------
networks:
  devnet:
    driver: bridge
